{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c983381",
   "metadata": {},
   "source": [
    "<h3>Import libraries:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73d2b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import roboticstoolbox as rtb\n",
    "from spatialmath import SE3, base, SO3\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi, degrees, radians\n",
    "import numpy as np\n",
    "from spatialmath.base import tr2rpy\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import spatialgeometry as sg\n",
    "import time\n",
    "import math\n",
    "from IPython.display import HTML\n",
    "\n",
    "# https://stackoverflow.com/questions/44116194/import-a-function-from-another-ipynb-file\n",
    "from ipynb.fs.full.inverse_kinematics_dnb_robot import *\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bcc6c2",
   "metadata": {},
   "source": [
    "<h3>Define the robot:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9541cb1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DHRobot: D&B Robot, 4 joints (RRRR), dynamics, standard DH parameters\n",
      "┌────────────┬───────┬───────┬───────┬──────┬────────┐\n",
      "│     θⱼ     │  dⱼ   │  aⱼ   │  ⍺ⱼ   │  q⁻  │   q⁺   │\n",
      "├────────────┼───────┼───────┼───────┼──────┼────────┤\n",
      "│  q1 - 90°  │ 14.09 │     0 │ 90.0° │ 0.0° │ 180.0° │\n",
      "│  q2        │     0 │ 12.72 │  0.0° │ 0.0° │ 180.0° │\n",
      "│  q3 - 126° │     0 │ 10.22 │  0.0° │ 0.0° │ 180.0° │\n",
      "│  q4        │     0 │  11.2 │  0.0° │ 0.0° │ 180.0° │\n",
      "└────────────┴───────┴───────┴───────┴──────┴────────┘\n",
      "\n",
      "┌──────┬──────────────────────────────────────┐\n",
      "│ tool │ t = 0, -8.4, 0; rpy/xyz = 0°, 0°, 0° │\n",
      "└──────┴──────────────────────────────────────┘\n",
      "\n",
      "┌──────┬──────┬──────┬─────┬───────┐\n",
      "│ name │ q0   │ q1   │ q2  │ q3    │\n",
      "├──────┼──────┼──────┼─────┼───────┤\n",
      "│ home │  90° │  80° │  0° │  120° │\n",
      "└──────┴──────┴──────┴─────┴───────┘\n",
      "\n",
      "Robot is in 1:1 scale.\n"
     ]
    }
   ],
   "source": [
    "# Define the lenghts\n",
    "l1 = 14.085\n",
    "l2 = 12.725\n",
    "l3 = 10.222\n",
    "l4 = 11.200\n",
    "l5 = 8.400\n",
    "\n",
    "# Adjust the lenghts to plot the robot properly with the library (otherwise, the axes are too small)\n",
    "# https://la.mathworks.com/matlabcentral/answers/485353-frames-not-appearing-using-robotics-system-toolbox\n",
    "# scaleFactor = 50\n",
    "scaleFactor = 1\n",
    "\n",
    "l1 /= scaleFactor\n",
    "l2 /= scaleFactor\n",
    "l3 /= scaleFactor\n",
    "l4 /= scaleFactor\n",
    "l5 /= scaleFactor\n",
    "\n",
    "# Notes:\n",
    "# 1. For a revolute joint the theta parameter of the link is ignored, and q used instead.\n",
    "# 2. For a prismatic joint the d parameter of the link is ignored, and q used instead.\n",
    "# 3. The joint offset parameter is added to q before computation of the transformation matrix.\n",
    "\n",
    "# Robot's links\n",
    "link1 = rtb.RevoluteDH(d=l1, a=0.0, alpha=pi/2, offset=-pi/2, qlim=[0,pi])\n",
    "link2 = rtb.RevoluteDH(d=0.0, a=l2, alpha=0.0, offset=0.0, qlim=[0,pi])\n",
    "link3 = rtb.RevoluteDH(d=0.0, a=l3, alpha=0.0, offset=-radians(126), qlim=[0,pi])\n",
    "link4 = rtb.RevoluteDH(d=0.0, a=l4, alpha=0.0, offset=0.0, qlim=[0,pi])\n",
    "\n",
    "# https://petercorke.github.io/robotics-toolbox-python/arm_dh.html#roboticstoolbox.robot.DHLink.PrismaticDH\n",
    "\n",
    "# Create the robot\n",
    "robot = rtb.DHRobot(\n",
    "    links=[link1, link2, link3, link4],\n",
    "    name=\"D&B Robot\",\n",
    "    tool = SE3.Ty(-l5)\n",
    "    )\n",
    "\n",
    "# Home angles\n",
    "qHome = [radians(90), radians(80), radians(0), radians(120)]\n",
    "\n",
    "# Set home position\n",
    "robot.addconfiguration_attr('home',qHome)\n",
    "\n",
    "print(robot)\n",
    "print(f'Robot is in 1:{scaleFactor} scale.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93e0d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot home position\n",
    "fig1 = plt.figure(figsize=(8, 8))  # Adjust this for larger or smaller axes\n",
    "robot.plot(q=robot.home, backend='pyplot', fig = fig1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a63a38",
   "metadata": {},
   "source": [
    "<h3>Kinematics tests:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c774fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[38;5;1m 0.2756  \u001b[0m \u001b[38;5;1m-0.9613  \u001b[0m \u001b[38;5;1m 0       \u001b[0m \u001b[38;5;4m 20.47   \u001b[0m  \u001b[0m\n",
      "  \u001b[38;5;1m 0       \u001b[0m \u001b[38;5;1m 0       \u001b[0m \u001b[38;5;1m-1       \u001b[0m \u001b[38;5;4m 0       \u001b[0m  \u001b[0m\n",
      "  \u001b[38;5;1m 0.9613  \u001b[0m \u001b[38;5;1m 0.2756  \u001b[0m \u001b[38;5;1m 0       \u001b[0m \u001b[38;5;4m 27.71   \u001b[0m  \u001b[0m\n",
      "  \u001b[38;5;244m 0       \u001b[0m \u001b[38;5;244m 0       \u001b[0m \u001b[38;5;244m 0       \u001b[0m \u001b[38;5;244m 1       \u001b[0m  \u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute the forward kinematics\n",
    "fk1 = robot.fkine(qHome)\n",
    "\n",
    "# Get the real coordinates\n",
    "fk1Escaled = SE3.Rt(fk1.R, fk1.t * scaleFactor)\n",
    "# This SE3.Rt method takes a rotation matrix R and a position vector t and creates the desired SE(3) transformation\n",
    "\n",
    "print(fk1Escaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3525d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1 = 90.0°.\n",
      "q2 = 80.0°.\n",
      "q3 = 0.0°.\n",
      "q4 = 120.0°.\n"
     ]
    }
   ],
   "source": [
    "# Compute the inverse kinematics\n",
    "ik1 = robot.ikine_LM(fk1, joint_limits = True)\n",
    "\n",
    "for i in range(len(ik1.q)):\n",
    "    print(f'q{i+1} = {round(degrees(ik1.q[i]),2)}°.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e42f5bc6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1: 90.0°.\n",
      "q2: 95.38°.\n",
      "q3: 88.93°.\n",
      "q4: -32.31°.\n"
     ]
    }
   ],
   "source": [
    "# We'll use our own inverse kinematics function which gives us easier control of the end effector's orientation\n",
    "\n",
    "pxHome = fk1.A[:,3][0]\n",
    "pyHome = fk1.A[:,3][1]\n",
    "pzHome = fk1.A[:,3][2]\n",
    "\n",
    "# The orientation of the end effector is defined with respect to the base frame (only the pitch angle can be controlled)\n",
    "pitchAngle = radians(0)\n",
    "\n",
    "qList = inverse_kinematics(pxHome, pyHome, pzHome, pitchAngle, scaleFactor)\n",
    "\n",
    "for index,q in enumerate(qList):\n",
    "    print(f'q{index+1}: {q}°.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97a7c506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint angles required to achieve the pose (orientation and position) of frame1:\n",
      "[66.66, 51.15, 16.45, 84.39]\n",
      "\n",
      "Homogeneous transformation matrix (HTM) of {frame1} with respect to the base frame {0}:\n",
      "  \u001b[38;5;1m 0.8253  \u001b[0m \u001b[38;5;1m-0.4024  \u001b[0m \u001b[38;5;1m-0.3962  \u001b[0m \u001b[38;5;4m 24.87   \u001b[0m  \u001b[0m\n",
      "  \u001b[38;5;1m-0.3561  \u001b[0m \u001b[38;5;1m 0.1736  \u001b[0m \u001b[38;5;1m-0.9182  \u001b[0m \u001b[38;5;4m-10.73   \u001b[0m  \u001b[0m\n",
      "  \u001b[38;5;1m 0.4382  \u001b[0m \u001b[38;5;1m 0.8989  \u001b[0m \u001b[38;5;1m 0       \u001b[0m \u001b[38;5;4m 12.65   \u001b[0m  \u001b[0m\n",
      "  \u001b[38;5;244m 0       \u001b[0m \u001b[38;5;244m 0       \u001b[0m \u001b[38;5;244m 0       \u001b[0m \u001b[38;5;244m 1       \u001b[0m  \u001b[0m\n",
      "\n",
      "Euler angles in the ZYX convention with respect to the mobile/current frame:\n",
      "- Roll: 90.0°.\n",
      "- Pitch: -25.99°.\n",
      "- Yaw: -23.34°.\n"
     ]
    }
   ],
   "source": [
    "# Traslation vector and pitch angle for frame1\n",
    "pxFrame1 = 19/scaleFactor\n",
    "pyFrame1 = -8.2/scaleFactor\n",
    "pzFrame1 = 0.2/scaleFactor\n",
    "pitchAngleFrame1 = radians(0)\n",
    "\n",
    "# Its orientation needs to be determined; it's only known that the pitch angle, in the RPY convention, is equal to zero (parallel to the surface)\n",
    "qFrame1 = inverse_kinematics(pxFrame1, pyFrame1, pzFrame1, pitchAngleFrame1, scaleFactor)\n",
    "TFrame1 = robot.fkine([radians(i) for i in qFrame1])\n",
    "\n",
    "print('Joint angles required to achieve the pose (orientation and position) of frame1:')\n",
    "print(qFrame1)\n",
    "\n",
    "print('\\nHomogeneous transformation matrix (HTM) of {frame1} with respect to the base frame {0}:')\n",
    "print(TFrame1)\n",
    "\n",
    "# Extract RPY angles (mobile/current frame, ZYX convention)\n",
    "rpyFrame1 = tr2rpy(TFrame1.R, order='zyx', unit='deg')\n",
    "\n",
    "print('Euler angles in the ZYX convention with respect to the mobile/current frame:')\n",
    "print(f'- Roll: {round(rpyFrame1[0],2)}°.')\n",
    "print(f'- Pitch: {round(rpyFrame1[1],2)}°.')\n",
    "print(f'- Yaw: {round(rpyFrame1[2],2)}°.')\n",
    "\n",
    "# mobile/current frame, ZYX convention = fixed frame, XYZ convention\n",
    "# https://mecademic.com/insights/academic-tutorials/space-orientation-euler-angles/\n",
    "# https://bdaiinstitute.github.io/spatialmath-python/func_3d.html#spatialmath.base.transforms3d.tr2rpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74f6389a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.25529983e+00  9.03383567e-01 -5.33660440e+00 -8.84709592e+00]\n",
      " [ 1.02879306e+00 -1.10227925e+00  6.51155112e+00  1.07949387e+01]\n",
      " [-4.12500880e-17 -1.62301966e+00 -9.68637890e+00 -1.09461981e+00]\n",
      " [-1.11022302e-16  7.73434764e-01  7.73434764e-01  7.73434764e-01]\n",
      " [ 0.00000000e+00  6.33875907e-01  6.33875907e-01  6.33875907e-01]\n",
      " [ 1.00000000e+00  6.12323400e-17  6.12323400e-17  6.12323400e-17]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the geometric jacobian with respect to the base frame\n",
    "jacob1 = robot.jacob0(qFrame1)\n",
    "print(jacob1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "186f3a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.66533454e-16  6.07237889e-01  1.26891237e+01  8.40000000e+00]\n",
      " [ 0.00000000e+00 -2.07281846e+00  1.92138472e+00  1.12000000e+01]\n",
      " [ 1.62301966e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00]\n",
      " [-8.44463238e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 5.35613517e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 6.12323400e-17  1.00000000e+00  1.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the geometric jacobian with respect to the end-effector frame\n",
    "jacob2 = robot.jacobe(qFrame1)\n",
    "print(jacob2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46e3dca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.25529983e+00  9.03383567e-01 -5.33660440e+00 -8.84709592e+00]\n",
      " [ 1.02879306e+00 -1.10227925e+00  6.51155112e+00  1.07949387e+01]\n",
      " [-4.12500880e-17 -1.62301966e+00 -9.68637890e+00 -1.09461981e+00]\n",
      " [ 1.31390192e-16  5.55111512e-16  5.55111512e-16  5.55111512e-16]\n",
      " [ 8.58685084e-17 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
      " [ 1.00000000e+00  6.66133815e-16  6.66133815e-16  6.66133815e-16]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the analytical jacobian with respect to the base frame\n",
    "jacob3 = robot.jacob0_analytical(qFrame1, representation='rpy/zyx')\n",
    "print(jacob3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043850f4",
   "metadata": {},
   "source": [
    "<h3>Trajectory test:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5fe9997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://petercorke.github.io/robotics-toolbox-python/arm_trajectory.html#roboticstoolbox.tools.trajectory.trapezoidal\n",
    "\n",
    "# https://la.mathworks.com/help/robotics/ref/trapveltraj.html\n",
    "# https://la.mathworks.com/help/robotics/ug/choose-trajectories-for-manipulator-paths.html\n",
    "# https://la.mathworks.com/help/robotics/ug/design-a-trajectory-with-velocity-limits-using-a-trapezoidal-velocity-profile.html\n",
    "# https://medium.com/mathworks/trajectory-planning-for-robot-manipulators-522404efb6f0\n",
    "\n",
    "# https://youtu.be/f3JVWqsDhbE?si=McvOoeyu82TyQrwv\n",
    "# https://youtu.be/Fd7wjZDoh7g?si=ZXw3PyyvvAwSEzFu\n",
    "\n",
    "# Servomotor MG996R ----> Operating speed: 0.17 s/60º (4.8 V), 0.14 s/60º (6 V) \n",
    "# 0.14 s/60º (6 V) --------> 7,14 °/s (max speed)\n",
    "\n",
    "# Set the time required to complete the trajectory\n",
    "timeStepsTraj1 = 100\n",
    "totalTime = 10 # Seconds\n",
    "timeTraj1 = np.linspace(0, totalTime, timeStepsTraj1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c4903fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the trajectory using a trapezoidal velocity profile\n",
    "# tg = rtb.tools.trapezoidal(pxHome*scaleFactor, pxFrame1*scaleFactor, timeTraj1)\n",
    "# tg.plot()\n",
    "\n",
    "# Generate the trajectory using a trapezoidal interpolator\n",
    "q0Traj1 = [i*scaleFactor for i in [pxHome, pyHome, pzHome]]\n",
    "q1Traj1 = [i*scaleFactor for i in [pxFrame1, pyFrame1, pzFrame1]]\n",
    "Traj1 = rtb.tools.trajectory.mtraj(rtb.tools.trapezoidal, q0Traj1, q1Traj1, timeTraj1)\n",
    "\n",
    "# Plot the position, velocity and acceleration data of the trajectory\n",
    "Traj1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a10ae04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure for 3D plotting\n",
    "fig2 = plt.figure()\n",
    "ax = fig2.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the 3D trajectory in the workspace\n",
    "ax.plot(Traj1.s[:,0], Traj1.s[:,1], Traj1.s[:,2])\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "ax.set_title('Task-space trajectory')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# We got a line in the cartesian space using a trapezoidal interpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8820f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's repeat the same process using a quintic polynomial interpolator\n",
    "\n",
    "# Generate the trajectory using a quintic polynomial interpolator\n",
    "Traj1v2 = rtb.tools.trajectory.mtraj(rtb.tools.quintic, q0Traj1, q1Traj1, timeTraj1)\n",
    "\n",
    "# Plot the position, velocity and acceleration data of the trajectory\n",
    "Traj1v2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1c17eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure for 3D plotting\n",
    "fig3 = plt.figure()\n",
    "ax = fig3.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the 3D trajectory in the workspace\n",
    "ax.plot(Traj1v2.s[:,0], Traj1v2.s[:,1], Traj1v2.s[:,2])\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "ax.set_title('Task-space trajectory')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# We got a line in the cartesian space using a quintic polynomial interpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fb51cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do it again with initial and final velocity different from zero (impractical in this case, it's just for testing)\n",
    "\n",
    "# Set the velocities (they could be different for each axis)\n",
    "dq0Traj1v3 = 0.5\n",
    "dq1Traj1v3 = 1\n",
    "\n",
    "Traj1v3x = rtb.tools.trajectory.quintic(q0Traj1[0], q1Traj1[0], timeTraj1, dq0Traj1v3, dq1Traj1v3)\n",
    "Traj1v3y = rtb.tools.trajectory.quintic(q0Traj1[1], q1Traj1[1], timeTraj1, dq0Traj1v3, dq1Traj1v3)\n",
    "Traj1v3z = rtb.tools.trajectory.quintic(q0Traj1[2], q1Traj1[2], timeTraj1, dq0Traj1v3, dq1Traj1v3)\n",
    "\n",
    "# Create a new figure for 3D plotting\n",
    "fig4 = plt.figure()\n",
    "ax = fig4.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the 3D trajectory in the workspace\n",
    "ax.plot(Traj1v3x.s, Traj1v3y.s, Traj1v3z.s)\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "ax.set_title('Task-space trajectory')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# We don't get a line in the cartesian space using a polynomial interpolator if the initial and final velocities are different from zero\n",
    "# This also happens between viapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad1354f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've only interpolated the position of the robot, but it's also required an orientation interpolation\n",
    "# Position and orientation interpolation are two different issues, therefore they're done separately\n",
    "\n",
    "# https://petercorke.github.io/robotics-toolbox-python/arm_trajectory.html#roboticstoolbox.tools.trajectory.ctraj\n",
    "# We'll handle position and orientation interpolation through the ctraj function\n",
    "\n",
    "# Set the time required to complete the trajectory\n",
    "timeStepsTraj2 = 120\n",
    "totalTime2 = 20 # Seconds\n",
    "timeTraj2 = np.linspace(0, totalTime2, timeStepsTraj2)\n",
    "\n",
    "# Compute the Cartesian trajectory between two poses (position + orientation)\n",
    "traj2 = rtb.tools.trajectory.ctraj(fk1, TFrame1, timeTraj2)\n",
    "\n",
    "# Afterwards, compute the inverse kinematics for each pose along the trajectory\n",
    "# These joint configurations can be fed into a control system to execute and control the movements of the robotic arm\n",
    "\n",
    "# qTraj2 = robot.ikine_LM(traj2)\n",
    "\n",
    "# Plot the trajectory with the library\n",
    "# robot.plot(qTraj2.q, backend='pyplot')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5762fc7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the evolution of each position vector component in the trajectory\n",
    "\n",
    "xTraj2 = traj2.x\n",
    "yTraj2 = traj2.y\n",
    "zTraj2 = traj2.z\n",
    "\n",
    "fig6, (ax1, ax2, ax3) = plt.subplots(3,1, sharex=True)\n",
    "fig6.suptitle('Evolution of each position vector component in the trajectory')\n",
    "\n",
    "ax1.plot(timeTraj2, xTraj2)\n",
    "ax1.set_ylabel('x')\n",
    "\n",
    "ax2.plot(timeTraj2, yTraj2)\n",
    "ax2.set_ylabel('y')\n",
    "\n",
    "ax3.plot(timeTraj2, zTraj2)\n",
    "ax3.set_ylabel('z')\n",
    "ax3.set_xlabel('t')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50076a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the evolution of each position vector component's velocity in the trajectory\n",
    "\n",
    "# Get the time step\n",
    "deltaT = timeTraj2[5] - timeTraj2[4]\n",
    "\n",
    "deltaX = np.hstack((0,np.diff(xTraj2, axis = 0)))\n",
    "deltaY = np.hstack((0,np.diff(yTraj2, axis = 0)))\n",
    "deltaZ = np.hstack((0,np.diff(zTraj2, axis = 0)))\n",
    "# Add zero at the start of the array to match the position array size\n",
    "\n",
    "velX = deltaX/deltaT\n",
    "velY = deltaY/deltaT\n",
    "velZ = deltaZ/deltaT\n",
    "\n",
    "fig7, (ax1, ax2, ax3) = plt.subplots(3,1, sharex=True)\n",
    "fig7.suptitle('Evolution of each position vector components velocity in the trajectory')\n",
    "\n",
    "ax1.plot(timeTraj2, velX)\n",
    "ax1.set_ylabel('x')\n",
    "\n",
    "ax2.plot(timeTraj2, velY)\n",
    "ax2.set_ylabel('y')\n",
    "\n",
    "ax3.plot(timeTraj2, velZ)\n",
    "ax3.set_ylabel('z')\n",
    "ax3.set_xlabel('t')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61678542",
   "metadata": {},
   "source": [
    "<h3>Resolved-Rate Motion Control:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77d03375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://youtu.be/sc5DZOkNvTc?si=JpxpIKR4r8iLLvUk\n",
    "# https://youtu.be/1GaxV8x4YHA?si=SVk1Yh55wbxU7_Xb\n",
    "# https://youtu.be/AgQ_Bybl_9k?si=KLwMJ_HOi7Fy8zhD\n",
    "# https://youtu.be/5lZD93jh2m0?si=QN1pOT8hGjsfnb5M\n",
    "# https://youtu.be/FU9jC1lHt_c?si=89MTK9BMjQouzqFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae6fa85",
   "metadata": {},
   "source": [
    "<h4>Method 1 (RRMC without velocity profile nor cartesian interpolation):</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6dbf8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the following notebook:\n",
    "# https://github.com/jhavl/dkt/blob/main/Part%201/3%20Resolved-Rate%20Motion%20Control.ipynb\n",
    "# https://arxiv.org/pdf/2207.01796"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19d59672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://youtu.be/-TUTqVOGSa8?si=3OldHsu_qE9i22FQ\n",
    "# https://youtu.be/s0NC85TAPaA?si=zr1ObUN9i66GhVMp\n",
    "# https://youtu.be/axEadpYSOv8?si=grupjc4v4PHLdA9d\n",
    "\n",
    "def error(currentPose, desiredPose):\n",
    "\n",
    "    # Returns the error between the desired and the current pose (position: vector, rotation: angle-axis notation)\n",
    "    # currentPose and desiredPose --> np.ndarray with shape = (4,4)\n",
    "    # currentPose and desiredPose are the poses of the end effector relative to the base frame\n",
    "    \n",
    "    # Error array\n",
    "    e = np.empty(6)\n",
    "\n",
    "    # The position error\n",
    "    e[:3] = desiredPose[:3, -1] - currentPose[:3, -1]\n",
    "\n",
    "    # The rotation error expressed as rotation matrix\n",
    "    R = desiredPose[:3, :3] @ currentPose[:3, :3].T\n",
    "\n",
    "    # Transform the rotation matrix to its Euler vector equivalent\n",
    "    \n",
    "    li = np.array([R[2, 1] - R[1, 2], R[0, 2] - R[2, 0], R[1, 0] - R[0, 1]])\n",
    "\n",
    "    if np.linalg.norm(li) < 1e-6:\n",
    "        # If li is a zero vector (or very close to it)\n",
    "\n",
    "        # Diagonal matrix case\n",
    "        if np.trace(R) > 0:\n",
    "            # (1,1,1) case\n",
    "            a = np.zeros((3,))\n",
    "        else:\n",
    "            a = np.pi / 2 * (np.diag(R) + 1)\n",
    "    else:\n",
    "        # Non-diagonal matrix case\n",
    "        ln = np.linalg.norm(li)\n",
    "        a = math.atan2(ln, np.trace(R) - 1) * li / ln\n",
    "    \n",
    "    # Append the rotation error expressed in the angle-axis representation in the error array\n",
    "    e[3:] = a\n",
    "\n",
    "    # Return the error\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df26bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_servo(currentPose, desiredPose, gain, threshold = 0.001):\n",
    "    \n",
    "    # Position-based servoing\n",
    "\n",
    "    # Returns the end-effector velocity in the cartesian space which will cause the robot to approach the desired pose\n",
    "\n",
    "    # currentPose: The current pose of the end-effecor in the base frame (ndarray)\n",
    "    # desiredPose: The desired pose of the end-effecor in the base frame (ndarray)\n",
    "    # gain: The gain for the proportional controller. A vector corresponding to each Cartesian axis (array-like)\n",
    "    # threshold: The threshold or tolerance of the final error between the robot's pose and desired pose (float)\n",
    "\n",
    "    # v: The velocity of the end-effector which will casue the robot to approach desiredPose (ndarray(6))\n",
    "    # arrived: True if the robot is within the threshold of the final pose (bool)\n",
    "    \n",
    "    if isinstance(currentPose, SE3):\n",
    "        currentPose = currentPose.A\n",
    "\n",
    "    if isinstance(desiredPose, SE3):\n",
    "        desiredPose = desiredPose.A\n",
    "\n",
    "    # Calculate the pose error vector\n",
    "    e = error(currentPose, desiredPose)\n",
    "\n",
    "    # Construct our gain diagonal matrix\n",
    "    if base.isscalar(gain):\n",
    "        k = gain * np.eye(6)\n",
    "    else:\n",
    "        k = np.diag(gain)\n",
    "\n",
    "    # Calculate our desired end-effector velocity\n",
    "    v = k @ e\n",
    "\n",
    "    # Check if we have arrived\n",
    "    arrived = True if np.sum(np.abs(e)) < threshold else False\n",
    "\n",
    "    # Tuple[np.ndarray, bool]\n",
    "    return v, arrived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2927474e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# https://github.com/petercorke/robotics-toolbox-python/blob/master/roboticstoolbox/examples/RRMC.py\n",
    "\n",
    "env = rtb.backends.PyPlot.PyPlot()\n",
    "env.launch('Resolved-Rate Motion Control Example')\n",
    "\n",
    "arrived = False\n",
    "\n",
    "env.add(robot)\n",
    "\n",
    "# Set the current pose\n",
    "robot.q = qHome\n",
    "\n",
    "# Desired pose\n",
    "pxFrame2 = 37/scaleFactor\n",
    "pyFrame2 = -8.2/scaleFactor\n",
    "pzFrame2 = 0.2/scaleFactor\n",
    "pitchAngleFrame2 = radians(0)\n",
    "\n",
    "# Its orientation needs to be determined; it's only known that the pitch angle, in the RPY convention, is equal to zero (parallel to the surface)\n",
    "qFrame2 = inverse_kinematics(pxFrame2, pyFrame2, pzFrame2, pitchAngleFrame2, scaleFactor)\n",
    "TFrame2 = robot.fkine([radians(i) for i in qFrame2])\n",
    "\n",
    "# Proportional control gain\n",
    "gain = 3\n",
    "\n",
    "# Time step\n",
    "dt = 0.05\n",
    "\n",
    "# Set the maximum end-effector velocity\n",
    "vMax = 1.0\n",
    "\n",
    "# Lists to save the values obtained in each time step\n",
    "posesObtained = []\n",
    "cartesianVelocitiesObtained = []\n",
    "jointPositionsObtained = []\n",
    "jointVelocitiesObtained = []\n",
    "\n",
    "while not arrived:\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    # HTM involved\n",
    "    currentPose = robot.fkine(robot.q)\n",
    "    desiredPose = TFrame2\n",
    "    \n",
    "    # Cartesian velocity required (both linear and angular velocities)\n",
    "    v, arrived = p_servo(currentPose, desiredPose, gain)\n",
    "    \n",
    "    # Calculate the magnitude of the end-effector velocity\n",
    "    vNorm = np.linalg.norm(v)\n",
    "\n",
    "    # If the end-effector velocity exceeds the maximum allowed\n",
    "    if vNorm > vMax:\n",
    "        v = (vMax / vNorm) * v\n",
    "\n",
    "    # Map it to joint velocities using the geometric jacobian relative to the base frame\n",
    "    qd = np.linalg.pinv(robot.jacob0(robot.q)) @ v\n",
    "    \n",
    "    # Apply the calculated joint velocity to the robot's actuators for movement\n",
    "    robot.qd = qd\n",
    "    \n",
    "    # Append the values obtained in this iteration\n",
    "    posesObtained.append(currentPose)\n",
    "    cartesianVelocitiesObtained.append(v)\n",
    "    jointPositionsObtained.append(robot.q)\n",
    "    jointVelocitiesObtained.append(qd)\n",
    "    \n",
    "    env.step(dt)\n",
    "    stop = time.time()\n",
    "    \n",
    "    if stop - start < dt:\n",
    "        time.sleep(dt - (stop - start))\n",
    "\n",
    "# robot.plot(q=[radians(i) for i in qFrame2], backend='pyplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d1eb69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure for 3D plotting\n",
    "fig5 = plt.figure()\n",
    "ax1 = fig5.add_subplot(111, projection='3d')\n",
    "# ax2 = fig5.add_subplot(122, projection='3d')\n",
    "\n",
    "# Plot the 3D trajectory for the translational motion in the workspace\n",
    "for htm in posesObtained:\n",
    "    ax1.scatter(htm.A[0,3], htm.A[1,3], htm.A[2,3])\n",
    "\n",
    "# Plot the desired pose\n",
    "ax1.scatter(TFrame2.A[0,3], TFrame2.A[1,3], TFrame2.A[2,3], marker=\"*\", linewidths=3, c='r')\n",
    "\n",
    "# Add labels and title\n",
    "ax1.set_xlabel('X Label')\n",
    "ax1.set_ylabel('Y Label')\n",
    "ax1.set_zlabel('Z Label')\n",
    "ax1.set_title('Task-space trajectory')\n",
    "\n",
    "# for vel in cartesianVelocitiesObtained:\n",
    "#     ax2.scatter(vel[0], vel[1], vel[2])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "834c6cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time spent in the trajectory\n",
    "t = np.arange(0, len(cartesianVelocitiesObtained)*dt, dt)\n",
    "\n",
    "fig8, (ax1, ax2) = plt.subplots(2,1, sharex=True)\n",
    "fig8.suptitle('Trajectory')\n",
    "\n",
    "ax1.plot(t, [pose.x for pose in posesObtained], label='x')\n",
    "ax1.plot(t, [pose.y for pose in posesObtained], label='y')\n",
    "ax1.plot(t, [pose.z for pose in posesObtained], label='z')\n",
    "ax1.set_ylabel('Position')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(t, [velocity[0] for velocity in cartesianVelocitiesObtained], label='vx')\n",
    "ax2.plot(t, [velocity[1] for velocity in cartesianVelocitiesObtained], label='vy')\n",
    "ax2.plot(t, [velocity[2] for velocity in cartesianVelocitiesObtained], label='vz')\n",
    "ax2.set_ylabel('Velocity')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a65760",
   "metadata": {},
   "source": [
    "<h4>Method 2 (RRMC with position and velocity profiles):</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d592180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=5lZD93jh2m0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d208563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_matrix_to_angle_axis_repr(R):\n",
    "    \n",
    "    # Transform the rotation matrix to its Euler vector equivalent\n",
    "    \n",
    "    li = np.array([R[2, 1] - R[1, 2], R[0, 2] - R[2, 0], R[1, 0] - R[0, 1]])\n",
    "\n",
    "    if np.linalg.norm(li) < 1e-6:\n",
    "        # If li is a zero vector (or very close to it)\n",
    "\n",
    "        # Diagonal matrix case\n",
    "        if np.trace(R) > 0:\n",
    "            # (1,1,1) case\n",
    "            a = np.zeros((3,))\n",
    "        else:\n",
    "            a = np.pi / 2 * (np.diag(R) + 1)\n",
    "    else:\n",
    "        # Non-diagonal matrix case\n",
    "        ln = np.linalg.norm(li)\n",
    "        a = math.atan2(ln, np.trace(R) - 1) * li / ln\n",
    "\n",
    "    return a\n",
    "\n",
    "def pose_error(currentPose, desiredPose):\n",
    "\n",
    "    # Returns the error between the desired and the current pose (position: vector, orientation: angle-axis notation)\n",
    "    # currentPose and desiredPose --> np.ndarray with shape = (4,4)\n",
    "    # currentPose and desiredPose are the poses of the end effector relative to the base frame\n",
    "    \n",
    "    if isinstance(currentPose, SE3):\n",
    "        currentPose = currentPose.A\n",
    "\n",
    "    if isinstance(desiredPose, SE3):\n",
    "        desiredPose = desiredPose.A\n",
    "\n",
    "    # Error array\n",
    "    e = np.empty(6)\n",
    "\n",
    "    # The position error\n",
    "    e[:3] = desiredPose[:3, -1] - currentPose[:3, -1]\n",
    "\n",
    "    # The rotation error expressed as rotation matrix\n",
    "    R = desiredPose[:3, :3] @ currentPose[:3, :3].T\n",
    "\n",
    "    # Transform the rotation matrix to its Euler vector equivalent\n",
    "    a = rotation_matrix_to_angle_axis_repr(R)\n",
    "    \n",
    "    # Append the rotation error expressed in the angle-axis representation in the error array\n",
    "    e[3:] = a\n",
    "\n",
    "    # Return the error\n",
    "    # e.shape = (6,)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e0712ef0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the HTM for the initial configuration of the robot in the trajectory\n",
    "T0 = robot.fkine(qHome)\n",
    "\n",
    "# Get the desired pose\n",
    "pxT1 = 31.67/scaleFactor\n",
    "pyT1 = 0/scaleFactor\n",
    "pzT1 = 13.6/scaleFactor\n",
    "pitchAngleT1 = radians(-4.0)\n",
    "\n",
    "# Its orientation needs to be determined; it's only known that the pitch angle, in the RPY convention, is equal to zero (parallel to the surface)\n",
    "qT1 = inverse_kinematics(pxT1, pyT1, pzT1, pitchAngleT1, scaleFactor)\n",
    "T1 = robot.fkine([radians(i) for i in qT1])\n",
    "\n",
    "# type(T0) and type(T1) ----> spatialmath.pose3d.SE3\n",
    "\n",
    "# Set time step in seconds\n",
    "dt = 0.2\n",
    "\n",
    "# Total time in seconds\n",
    "totalTime = 8\n",
    "\n",
    "# Time array\n",
    "trajTime = np.arange(0, totalTime, dt)\n",
    "\n",
    "# Number of steps\n",
    "stepsNum = len(trajTime)\n",
    "\n",
    "# https://petercorke.github.io/robotics-toolbox-python/arm_trajectory.html#roboticstoolbox.tools.trajectory.trapezoidal\n",
    "# Generate the trapezoidal trajectory for the translational components\n",
    "x = rtb.tools.trajectory.trapezoidal(T0.A[0,3], T1.A[0,3], trajTime)\n",
    "y = rtb.tools.trajectory.trapezoidal(T0.A[1,3], T1.A[1,3], trajTime)\n",
    "z = rtb.tools.trajectory.trapezoidal(T0.A[2,3], T1.A[2,3], trajTime)\n",
    "# Unit = [cm]\n",
    "\n",
    "# Velocities of the translational components along the trajectory (linear velocities)\n",
    "vx = x.qd\n",
    "vy = y.qd\n",
    "vz = z.qd\n",
    "# Unit = [cm/s]\n",
    "\n",
    "# Transform the initial and final rotation matrices to angle-axis representation\n",
    "angAxisT0 = rotation_matrix_to_angle_axis_repr(T0.R)\n",
    "angAxisT1 = rotation_matrix_to_angle_axis_repr(T1.R)\n",
    "\n",
    "# Generate the trapezoidal trajectory for the orientation components in angle-axis representation form\n",
    "angx = rtb.tools.trajectory.trapezoidal(angAxisT0[0], angAxisT1[0], trajTime)\n",
    "angy = rtb.tools.trajectory.trapezoidal(angAxisT0[1], angAxisT1[1], trajTime)\n",
    "angz = rtb.tools.trajectory.trapezoidal(angAxisT0[2], angAxisT1[2], trajTime)\n",
    "angs = [np.array([angx.q[i], angy.q[i], angz.q[i]])for i in range(len(angx))]\n",
    "# Unit = [rad]\n",
    "\n",
    "# Get the angular velocities\n",
    "wx = angx.qd\n",
    "wy = angy.qd\n",
    "wz = angz.qd\n",
    "# Unit = [rad/s]\n",
    "\n",
    "# Transform the trajectory represented in angle-axis form to rotation matrix\n",
    "rotMatrix = [(SO3.AngleAxis(np.linalg.norm(angs[i]),angs[i]/np.linalg.norm(angs[i]))).R for i in range(len(trajTime))]\n",
    "\n",
    "# https://www.euclideanspace.com/physics/kinematics/angularvelocity/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2706e4d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot all the calculated parameters\n",
    "\n",
    "fig9, axes = plt.subplots(2,2) \n",
    "# plt.subplots(2, 2) returns a 2x2 array of axes\n",
    "\n",
    "# Unpack the axes array into individual variables\n",
    "(ax1, ax2), (ax3, ax4) = axes\n",
    "\n",
    "fig9.suptitle('Trajectory')\n",
    "\n",
    "ax1.plot(trajTime, x.q, label='x')\n",
    "ax1.plot(trajTime, y.q, label='y')\n",
    "ax1.plot(trajTime, z.q, label='z')\n",
    "ax1.set_ylabel('Position')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(trajTime, x.qd, label='vx')\n",
    "ax2.plot(trajTime, y.qd, label='vy')\n",
    "ax2.plot(trajTime, z.qd, label='vz')\n",
    "ax2.set_ylabel('Linear velocity')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.legend()\n",
    "\n",
    "ax3.plot(trajTime, angx.q, label='x-axis rotation')\n",
    "ax3.plot(trajTime, angy.q, label='y-axis rotation')\n",
    "ax3.plot(trajTime, angz.q, label='z-axis rotation')\n",
    "ax3.set_ylabel('Angular position')\n",
    "ax3.set_xlabel('Time')\n",
    "ax3.legend()\n",
    "\n",
    "ax4.plot(trajTime, wx, label='wx')\n",
    "ax4.plot(trajTime, wy, label='wy')\n",
    "ax4.plot(trajTime, wz, label='wz')\n",
    "ax4.set_ylabel('Angular velocity')\n",
    "ax4.set_xlabel('Time')\n",
    "ax4.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "88805214",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create the homogeneous transformation matrices using the rotation matrices and translation vectors from the trajectory\n",
    "XRef = [SE3.Rt(rotMatrix[j], np.array([x.q[j], y.q[j], z.q[j]])) for j in range(len(trajTime))]\n",
    "\n",
    "# Organize the velocities to ease its manipulation\n",
    "XdRef = [np.array([vx[i], vy[i], vz[i], wx[i], wy[i], wz[i]]) for i in range(len(trajTime))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1920bc09",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.]\n",
      "[-2.15382324e-05  1.46646547e-03  1.18862561e-02 -2.66275005e-02]\n",
      "[-2.70690479e-05  4.51428970e-03  2.08964150e-02 -5.04149206e-02]\n",
      "[-2.91194833e-05  7.69835098e-03  2.95988664e-02 -7.37239345e-02]\n",
      "[-3.01719906e-05  1.06546021e-02  3.86152069e-02 -9.70611057e-02]\n",
      "[-3.06816165e-05  1.32225297e-02  4.81843808e-02 -1.20555891e-01]\n",
      "[-3.07101437e-05  1.52711174e-02  5.84720958e-02 -1.44254242e-01]\n",
      "[-3.02541151e-05  1.66628191e-02  6.96333457e-02 -1.68176695e-01]\n",
      "[-2.93102345e-05  1.72455611e-02  8.18258449e-02 -1.92330066e-01]\n",
      "[-2.78881407e-05  1.68511737e-02  9.52138145e-02 -2.16710870e-01]\n",
      "[-2.60123449e-05  1.52959762e-02  1.09970219e-01 -2.41308313e-01]\n",
      "[-2.37216130e-05  1.23825891e-02  1.26279373e-01 -2.66108679e-01]\n",
      "[-2.10674900e-05  7.90256655e-03  1.44340714e-01 -2.91101668e-01]\n",
      "[-1.81123834e-05  1.63934463e-03  1.64374485e-01 -3.16288932e-01]\n",
      "[ 1.01289647e-06 -3.96682845e-03  1.69566180e-01 -3.14002951e-01]\n",
      "[ 5.50233639e-06 -1.12942788e-02  1.77713361e-01 -3.14473652e-01]\n",
      "[ 7.25361789e-06 -1.91949216e-02  1.86735219e-01 -3.15542321e-01]\n",
      "[ 8.37036037e-06 -2.73771517e-02  1.96186270e-01 -3.16809731e-01]\n",
      "[ 9.23445411e-06 -3.57667112e-02  2.06006487e-01 -3.18240952e-01]\n",
      "[ 9.92471144e-06 -4.43482088e-02  2.16232587e-01 -3.19878194e-01]\n",
      "[ 1.04661192e-05 -5.31276645e-02  2.26934206e-01 -3.21783044e-01]\n",
      "[ 1.08734196e-05 -6.21247962e-02  2.38202270e-01 -3.24026271e-01]\n",
      "[ 1.11587334e-05 -7.13727966e-02  2.50150229e-01 -3.26688026e-01]\n",
      "[ 1.13329447e-05 -8.09205076e-02  2.62919701e-01 -3.29861070e-01]\n",
      "[ 1.14060095e-05 -9.08361381e-02  2.76689373e-01 -3.33655890e-01]\n",
      "[ 1.13870730e-05 -1.01212867e-01  2.91688056e-01 -3.38208157e-01]\n",
      "[ 1.12845488e-05 -1.12177290e-01  3.08214086e-01 -3.43689669e-01]\n",
      "[ 2.19825742e-05 -1.10684976e-01  2.95377380e-01 -3.18978677e-01]\n",
      "[ 2.25801001e-05 -1.09574415e-01  2.83924782e-01 -2.96816758e-01]\n",
      "[ 2.14528440e-05 -1.07208021e-01  2.70948426e-01 -2.74708174e-01]\n",
      "[ 2.01131300e-05 -1.03176660e-01  2.55561021e-01 -2.51930771e-01]\n",
      "[ 1.88373100e-05 -9.73695992e-02  2.37383473e-01 -2.28167903e-01]\n",
      "[ 1.76751847e-05 -8.97504623e-02  2.16177470e-01 -2.03207951e-01]\n",
      "[ 1.66331987e-05 -8.03156225e-02  1.91781872e-01 -1.76890953e-01]\n",
      "[ 1.57083206e-05 -6.91012868e-02  1.64133734e-01 -1.49116343e-01]\n",
      "[ 1.48947068e-05 -5.62046953e-02  1.33315388e-01 -1.19867651e-01]\n",
      "[ 1.41853152e-05 -4.18073597e-02  9.96049216e-02 -8.92395650e-02]\n",
      "[ 1.35725237e-05 -2.61915786e-02  6.35114503e-02 -5.74567203e-02]\n",
      "[ 1.30485120e-05 -9.74152304e-03  2.57759815e-02 -2.48735277e-02]\n",
      "[ 1.26055612e-05  7.07734487e-03 -1.26760694e-02  8.05265918e-03]\n",
      "[ 2.52797827e-06  1.40654407e-03 -2.51401884e-03  1.59826171e-03]\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/petercorke/robotics-toolbox-python/blob/master/roboticstoolbox/examples/RRMC.py\n",
    "\n",
    "env2 = rtb.backends.PyPlot.PyPlot()\n",
    "env2.launch('Resolved-Rate Motion Control Example')\n",
    "\n",
    "arrived = False\n",
    "\n",
    "env2.add(robot)\n",
    "\n",
    "# Set the starting pose in the robot\n",
    "robot.q = qHome\n",
    "\n",
    "# Proportional control gain\n",
    "gain = 4\n",
    "\n",
    "# Construct our gain diagonal matrix\n",
    "if base.isscalar(gain):\n",
    "    kp = gain * np.eye(6)\n",
    "else:\n",
    "    kp = np.diag(gain)\n",
    "    \n",
    "threshold = 0.5\n",
    "\n",
    "i = 0 # Auxiliar variable\n",
    "\n",
    "# Lists to save the values obtained in each time step\n",
    "posesObtained = []\n",
    "cartesianVelocitiesObtained = []\n",
    "jointPositionsObtained = []\n",
    "jointVelocitiesObtained = []\n",
    "\n",
    "while not arrived:\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # Current robot's pose\n",
    "    currentPose = robot.fkine(robot.q)\n",
    "\n",
    "    if i < len(XRef):\n",
    "        # Desired pose  in this specific time step:\n",
    "        desiredPose = XRef[i]\n",
    "        actualXdRef = XdRef[i]\n",
    "    else:\n",
    "        # If all trajectory points have been processed, ensure the robot's final pose is achieved correctly\n",
    "        desiredPose = XRef[-1]\n",
    "        actualXdRef = XdRef[-1]\n",
    "        \n",
    "    # Compute the position error\n",
    "    poseError = pose_error(currentPose, desiredPose)\n",
    "    \n",
    "    # Compute the combined term (feedforward + feedback)\n",
    "    referenceVelocityAdjusted = actualXdRef + (kp @ poseError)\n",
    "    \n",
    "    # Use this term to calculate joint velocities using the geometric jacobian relative to the base frame\n",
    "    qd = np.linalg.pinv(robot.jacob0(robot.q)) @ referenceVelocityAdjusted\n",
    "    print(qd)\n",
    "    \n",
    "    # Apply the calculated joint velocity to the robot's actuators for movement\n",
    "    robot.qd = qd\n",
    "    \n",
    "    if i >= len(XRef):\n",
    "        # Check if the robotic arm has reached the desired point\n",
    "        arrived = True if np.sum(np.abs(poseError)) < threshold else False\n",
    "\n",
    "    # Update the auxiliar variable\n",
    "    i += 1\n",
    "    \n",
    "    # Append the values obtained in this iteration\n",
    "    posesObtained.append(currentPose)\n",
    "    cartesianVelocitiesObtained.append(referenceVelocityAdjusted)\n",
    "    jointPositionsObtained.append((robot.q).copy())\n",
    "    jointVelocitiesObtained.append(qd)\n",
    "    \n",
    "    env2.step(dt)\n",
    "    stop = time.time()\n",
    "    \n",
    "    # Complete the time step\n",
    "    if stop - start < dt:\n",
    "        time.sleep(dt - (stop - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0d3878b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure for 3D plotting\n",
    "fig10 = plt.figure()\n",
    "ax1 = fig10.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the 3D trajectory for the translational motion in the workspace\n",
    "for htm in posesObtained:\n",
    "    ax1.scatter(htm.A[0,3], htm.A[1,3], htm.A[2,3])\n",
    "\n",
    "# Plot the desired pose\n",
    "ax1.scatter(T1.A[0,3], T1.A[1,3], T1.A[2,3], marker=\"*\", linewidths=3, c='r')\n",
    "\n",
    "# Add labels and title\n",
    "ax1.set_xlabel('X Label')\n",
    "ax1.set_ylabel('Y Label')\n",
    "ax1.set_zlabel('Z Label')\n",
    "ax1.set_title('Task-space trajectory')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f107e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the obtained parameters\n",
    "\n",
    "# Ignore the time in these plots\n",
    "\n",
    "fig11, axes = plt.subplots(2,2)\n",
    "(ax1, ax2), (ax3, ax4) = axes\n",
    "fig11.suptitle('Trajectory')\n",
    "\n",
    "ax1.plot([pose.x for pose in posesObtained], label='x')\n",
    "ax1.plot([pose.y for pose in posesObtained], label='y')\n",
    "ax1.plot([pose.z for pose in posesObtained], label='z')\n",
    "ax1.set_ylabel('Cartesian positions')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot([velocity[0] for velocity in cartesianVelocitiesObtained], label='vx')\n",
    "ax2.plot([velocity[1] for velocity in cartesianVelocitiesObtained], label='vy')\n",
    "ax2.plot([velocity[2] for velocity in cartesianVelocitiesObtained], label='vz')\n",
    "ax2.plot([velocity[3] for velocity in cartesianVelocitiesObtained], label='wx')\n",
    "ax2.plot([velocity[4] for velocity in cartesianVelocitiesObtained], label='wy')\n",
    "ax2.plot([velocity[5] for velocity in cartesianVelocitiesObtained], label='wz')\n",
    "ax2.set_ylabel('Cartesian velocities')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.legend()\n",
    "\n",
    "ax3.plot([q[0] for q in jointPositionsObtained], label='q1')\n",
    "ax3.plot([q[1] for q in jointPositionsObtained], label='q2')\n",
    "ax3.plot([q[2] for q in jointPositionsObtained], label='q3')\n",
    "ax3.plot([q[3] for q in jointPositionsObtained], label='q4')\n",
    "ax3.set_ylabel('Joint positions')\n",
    "ax3.set_xlabel('Time')\n",
    "ax3.legend()\n",
    "\n",
    "ax4.plot([qd[0] for qd in jointVelocitiesObtained], label='qd1')\n",
    "ax4.plot([qd[1] for qd in jointVelocitiesObtained], label='qd2')\n",
    "ax4.plot([qd[2] for qd in jointVelocitiesObtained], label='qd3')\n",
    "ax4.plot([qd[3] for qd in jointVelocitiesObtained], label='qd4')\n",
    "ax4.set_ylabel('Joint velocities')\n",
    "ax4.set_xlabel('Time')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e4cfd69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0005699686379645871,\n",
       " 0.010273557334711417,\n",
       " -0.01162305427477817,\n",
       " -0.0023890609369878737]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(qd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f85c89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
